"""
Report generation for AI Red Team Simulation.

Generates Markdown and JSON reports from suite execution results,
providing detailed analysis, metrics, and evidence.
"""

from __future__ import annotations

import json
from datetime import datetime
from pathlib import Path
from typing import Optional

from airtsim.models import (
    SuiteResult,
    TestResult,
    AttackKind,
    Severity,
)


class ReportGenerator:
    """
    Generates formatted reports from suite execution results.
    
    Supports:
    - JSON reports for programmatic consumption
    - Markdown reports for human review
    """
    
    def __init__(self, output_dir: str | Path = "reports"):
        """
        Initialize the report generator.
        
        Args:
            output_dir: Directory for report output.
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def generate(
        self,
        result: SuiteResult,
        report_name: str = "latest_report",
    ) -> tuple[Path, Path]:
        """
        Generate both JSON and Markdown reports.
        
        Args:
            result: Suite execution results.
            report_name: Base name for report files.
            
        Returns:
            Tuple of (json_path, markdown_path)
        """
        json_path = self.generate_json(result, report_name)
        md_path = self.generate_markdown(result, report_name)
        
        return json_path, md_path
    
    def generate_json(
        self,
        result: SuiteResult,
        report_name: str = "latest_report",
    ) -> Path:
        """
        Generate JSON report.
        
        Args:
            result: Suite execution results.
            report_name: Base name for report file.
            
        Returns:
            Path to generated JSON file.
        """
        json_path = self.output_dir / f"{report_name}.json"
        
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(result.to_dict(), f, indent=2, default=str)
        
        return json_path
    
    def generate_markdown(
        self,
        result: SuiteResult,
        report_name: str = "latest_report",
    ) -> Path:
        """
        Generate Markdown report.
        
        Args:
            result: Suite execution results.
            report_name: Base name for report file.
            
        Returns:
            Path to generated Markdown file.
        """
        md_path = self.output_dir / f"{report_name}.md"
        
        content = self._build_markdown(result)
        
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(content)
        
        return md_path
    
    def _build_markdown(self, result: SuiteResult) -> str:
        """Build Markdown report content."""
        lines = []
        
        # Header
        lines.append(f"# AI Red Team Simulation Report")
        lines.append("")
        lines.append(f"**Suite:** {result.suite_name}")
        lines.append(f"**Target:** {result.target_name}")
        lines.append(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        
        # Configuration
        lines.append("## Configuration")
        lines.append("")
        lines.append(f"- **Mitigations Enabled:** {'âœ… Yes' if result.mitigations_enabled else 'âŒ No'}")
        lines.append(f"- **Duration:** {result.duration_seconds:.2f} seconds")
        lines.append(f"- **Total Test Cases:** {result.metrics.total_cases}")
        lines.append("")
        
        # Executive Summary
        lines.append("## Executive Summary")
        lines.append("")
        
        asr_emoji = "ðŸ”´" if result.metrics.overall_asr > 0.5 else "ðŸŸ¡" if result.metrics.overall_asr > 0.2 else "ðŸŸ¢"
        lines.append(f"### Overall Attack Success Rate: {asr_emoji} {result.metrics.overall_asr:.1%}")
        lines.append("")
        
        if result.metrics.overall_asr > 0.5:
            lines.append("> âš ï¸ **HIGH RISK**: More than half of the attack tests succeeded. Significant security improvements needed.")
        elif result.metrics.overall_asr > 0.2:
            lines.append("> âš¡ **MODERATE RISK**: Some attack tests succeeded. Review and address vulnerabilities.")
        else:
            lines.append("> âœ… **LOW RISK**: Most attacks were blocked. Continue monitoring and testing.")
        lines.append("")
        
        # Summary Table
        lines.append("## Summary Table")
        lines.append("")
        lines.append("| Metric | Value |")
        lines.append("|--------|-------|")
        lines.append(f"| Total Cases | {result.metrics.total_cases} |")
        lines.append(f"| Successful Attacks | {result.metrics.successful_attacks} |")
        lines.append(f"| Failed Attacks | {result.metrics.failed_attacks} |")
        lines.append(f"| Leaks Detected | {result.metrics.leaks_detected} |")
        lines.append(f"| Injections Detected | {result.metrics.injections_detected} |")
        lines.append(f"| Overall ASR | {result.metrics.overall_asr:.1%} |")
        lines.append("")
        
        # ASR by Attack Kind
        if result.metrics.asr_by_kind:
            lines.append("### Attack Success Rate by Category")
            lines.append("")
            lines.append("| Attack Type | ASR | Risk Level |")
            lines.append("|-------------|-----|------------|")
            for kind, asr in result.metrics.asr_by_kind.items():
                risk = "ðŸ”´ High" if asr > 0.5 else "ðŸŸ¡ Medium" if asr > 0.2 else "ðŸŸ¢ Low"
                lines.append(f"| {kind.replace('_', ' ').title()} | {asr:.1%} | {risk} |")
            lines.append("")
        
        # Leak Types
        if result.metrics.leak_types:
            lines.append("### Data Leakage by Type")
            lines.append("")
            lines.append("| Leak Type | Count |")
            lines.append("|-----------|-------|")
            for leak_type, count in sorted(result.metrics.leak_types.items(), key=lambda x: -x[1]):
                lines.append(f"| {leak_type.replace('_', ' ').title()} | {count} |")
            lines.append("")
        
        # Severity Distribution
        if result.metrics.severity_counts:
            lines.append("### Severity Distribution")
            lines.append("")
            lines.append("| Severity | Count |")
            lines.append("|----------|-------|")
            severity_order = ["critical", "high", "medium", "low"]
            for sev in severity_order:
                if sev in result.metrics.severity_counts:
                    emoji = {"critical": "ðŸ”´", "high": "ðŸŸ ", "medium": "ðŸŸ¡", "low": "ðŸŸ¢"}.get(sev, "âšª")
                    lines.append(f"| {emoji} {sev.title()} | {result.metrics.severity_counts[sev]} |")
            lines.append("")
        
        # Detailed Results
        lines.append("## Detailed Test Results")
        lines.append("")
        
        for i, test_result in enumerate(result.results, 1):
            lines.extend(self._format_test_result(test_result, i))
        
        # Errors
        if result.errors:
            lines.append("## Errors")
            lines.append("")
            for error in result.errors:
                lines.append(f"- âŒ {error}")
            lines.append("")
        
        # Recommendations
        lines.append("## Recommendations")
        lines.append("")
        lines.extend(self._generate_recommendations(result))
        
        # Footer
        lines.append("---")
        lines.append("")
        lines.append("*Report generated by AI Red Team Simulation (airtsim)*")
        
        return "\n".join(lines)
    
    def _format_test_result(self, result: TestResult, index: int) -> list[str]:
        """Format a single test result for Markdown."""
        lines = []
        
        # Status emoji
        if result.error:
            status = "âš ï¸ Error"
        elif result.attack_success:
            status = "ðŸ”´ Attack Succeeded"
        else:
            status = "ðŸŸ¢ Attack Blocked"
        
        lines.append(f"### {index}. {result.test_id}")
        lines.append("")
        lines.append(f"**Status:** {status}")
        lines.append(f"**Attack Type:** {result.kind.value.replace('_', ' ').title()}")
        lines.append(f"**Severity:** {result.severity.value.title()}")
        lines.append(f"**Mitigations:** {'Enabled' if result.mitigations_enabled else 'Disabled'}")
        lines.append("")
        
        # Findings
        lines.append("**Findings:**")
        lines.append(f"- Attack Success: {'âœ… Yes' if result.attack_success else 'âŒ No'}")
        lines.append(f"- Leak Detected: {'âœ… Yes' if result.leak_detected else 'âŒ No'}")
        lines.append(f"- Injection Detected: {'âœ… Yes' if result.injection_detected else 'âŒ No'}")
        lines.append("")
        
        # Input
        lines.append("**User Input:**")
        lines.append("```")
        input_preview = result.user_input[:500]
        if len(result.user_input) > 500:
            input_preview += "... [truncated]"
        lines.append(input_preview)
        lines.append("```")
        lines.append("")
        
        # Response
        lines.append("**Response (excerpt):**")
        lines.append("```")
        response_preview = result.final_response[:500]
        if len(result.final_response) > 500:
            response_preview += "... [truncated]"
        lines.append(response_preview)
        lines.append("```")
        lines.append("")
        
        # Evidence
        if result.evidence:
            lines.append("**Evidence:**")
            if "mitigations" in result.evidence:
                mit = result.evidence["mitigations"]
                lines.append(f"- Input Sanitized: {mit.get('input_sanitized', False)}")
                lines.append(f"- Output Sanitized: {mit.get('output_sanitized', False)}")
                lines.append(f"- Blocked: {mit.get('blocked', False)}")
                lines.append(f"- DLP Findings: {mit.get('dlp_findings_count', 0)}")
            if "injection_detection" in result.evidence:
                inj = result.evidence["injection_detection"]
                if inj.get("reasons"):
                    lines.append(f"- Injection Patterns: {', '.join(inj['reasons'])}")
            if "dlp_findings" in result.evidence:
                for finding in result.evidence["dlp_findings"][:3]:  # Show first 3
                    lines.append(f"- DLP: {finding['type']} ({finding['severity']})")
            lines.append("")
        
        # Error
        if result.error:
            lines.append(f"**Error:** {result.error}")
            lines.append("")
        
        lines.append("---")
        lines.append("")
        
        return lines
    
    def _generate_recommendations(self, result: SuiteResult) -> list[str]:
        """Generate security recommendations based on results."""
        lines = []
        recommendations = []
        
        # Check for high ASR
        if result.metrics.overall_asr > 0.3:
            recommendations.append(
                "**Enable security mitigations**: Consider enabling input validation, "
                "output filtering, and policy enforcement to reduce attack success rate."
            )
        
        # Check for injection success
        prompt_inj_asr = result.metrics.asr_by_kind.get("prompt_injection", 0)
        indirect_inj_asr = result.metrics.asr_by_kind.get("indirect_injection", 0)
        
        if prompt_inj_asr > 0.2:
            recommendations.append(
                "**Strengthen prompt injection defenses**: Implement input sanitization, "
                "use structured prompts, and consider prompt firewalls."
            )
        
        if indirect_inj_asr > 0.2:
            recommendations.append(
                "**Secure RAG pipeline**: Sanitize retrieved documents, validate sources, "
                "and implement content filtering for retrieved context."
            )
        
        # Check for data leakage
        if result.metrics.leaks_detected > 0:
            recommendations.append(
                "**Implement DLP controls**: Deploy output scanning for sensitive data "
                "patterns (API keys, credentials, PII) and redact before returning responses."
            )
        
        # Check for critical/high severity
        critical_count = result.metrics.severity_counts.get("critical", 0)
        high_count = result.metrics.severity_counts.get("high", 0)
        
        if critical_count > 0 or high_count > 0:
            recommendations.append(
                "**Address high-severity findings**: Review and remediate critical and "
                "high severity issues as a priority."
            )
        
        # If mitigations were disabled
        if not result.mitigations_enabled:
            recommendations.append(
                "**Test with mitigations enabled**: Re-run tests with `--enable-mitigations` "
                "to evaluate the effectiveness of security controls."
            )
        
        # Default recommendation
        if not recommendations:
            recommendations.append(
                "**Continue monitoring**: Security posture appears reasonable. "
                "Continue regular testing and expand test coverage."
            )
        
        for i, rec in enumerate(recommendations, 1):
            lines.append(f"{i}. {rec}")
            lines.append("")
        
        return lines


def generate_reports(
    result: SuiteResult,
    output_dir: str | Path = "reports",
    report_name: str = "latest_report",
) -> tuple[Path, Path]:
    """
    Convenience function to generate reports.
    
    Args:
        result: Suite execution results.
        output_dir: Directory for output files.
        report_name: Base name for report files.
        
    Returns:
        Tuple of (json_path, markdown_path)
    """
    generator = ReportGenerator(output_dir)
    return generator.generate(result, report_name)
